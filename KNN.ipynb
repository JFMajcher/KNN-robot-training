{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (113, 240)\n",
    "def pixels_from_path(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    im = im.resize(IMG_SIZE)\n",
    "    np_im = np.array(im)\n",
    "    return np_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of images = 8192 \n",
    "\n",
    "Training set- 6554 images\n",
    "\n",
    "Testing set- 1638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_path = \"D:/Nauka/Magisterskie/!sem3/MSI/projekt/lewo/\"\n",
    "right_path = \"D:/Nauka/Magisterskie/!sem3/MSI/projekt/prawo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 3277\n",
    "left_train_set = np.asarray([pixels_from_path(left) for left in glob.glob(left_path + \"*\")[:sample_size]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3277"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(left_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_train_set = np.asarray([pixels_from_path(right) for right in glob.glob(right_path +\"*\")[:sample_size]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3277"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(right_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 819\n",
    "left_test_set = np.asarray([pixels_from_path(left) for left in glob.glob(left_path + \"*\")[-test_size:]])\n",
    "right_test_set = np.asarray([pixels_from_path(right) for right in glob.glob(right_path + \"*\")[-test_size:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "left 1\n",
    "\n",
    "right 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([left_train_set, right_train_set])\n",
    "labels_train = np.asarray([1 for _ in range(sample_size)] + [0 for _ in range(sample_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.concatenate([left_test_set, right_test_set])\n",
    "labels_test = np.asarray([1 for _ in range(test_size)] + [0 for _ in range (test_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6554, 240, 113, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6554,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1638, 240, 113, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1638,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 256\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "conv_inputs = keras.Input(shape = (img_size[1], img_size[0], 3), name='robo_cam_frame')\n",
    "\n",
    "conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(conv_inputs)\n",
    "conv_layer = layers.MaxPool2D(pool_size=(2,2))(conv_layer)\n",
    "\n",
    "conv_x = layers.Flatten(name = 'flattened_features')(conv_layer)\n",
    "\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(conv_x)\n",
    "conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(conv_x)\n",
    "conv_outputs =  layers.Dense(1, activation='sigmoid', name='class')(conv_x)\n",
    "\n",
    "conv_model = keras.Model(inputs = conv_inputs, outputs = conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr = 1e-6)\n",
    "conv_model.compile(optimizer=customAdam, loss=\"binary_crossentropy\", metrics = [\"binary_crossentropy\", \"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6554 samples, validate on 1638 samples\n",
      "Epoch 1/5\n",
      "6554/6554 [==============================] - 498s 76ms/sample - loss: 0.1854 - binary_crossentropy: 0.1854 - mean_squared_error: 0.0490 - val_loss: 0.0951 - val_binary_crossentropy: 0.0951 - val_mean_squared_error: 0.0262\n",
      "Epoch 2/5\n",
      "6554/6554 [==============================] - 471s 72ms/sample - loss: 0.1247 - binary_crossentropy: 0.1247 - mean_squared_error: 0.0327 - val_loss: 0.0913 - val_binary_crossentropy: 0.0913 - val_mean_squared_error: 0.0229\n",
      "Epoch 3/5\n",
      "6554/6554 [==============================] - 471s 72ms/sample - loss: 0.1338 - binary_crossentropy: 0.1338 - mean_squared_error: 0.0317 - val_loss: 0.0882 - val_binary_crossentropy: 0.0882 - val_mean_squared_error: 0.0245\n",
      "Epoch 4/5\n",
      "6554/6554 [==============================] - 460s 70ms/sample - loss: 0.0992 - binary_crossentropy: 0.0992 - mean_squared_error: 0.0238 - val_loss: 0.1285 - val_binary_crossentropy: 0.1285 - val_mean_squared_error: 0.0306\n",
      "Epoch 5/5\n",
      "6554/6554 [==============================] - 443s 68ms/sample - loss: 0.0711 - binary_crossentropy: 0.0711 - mean_squared_error: 0.0171 - val_loss: 0.1775 - val_binary_crossentropy: 0.1775 - val_mean_squared_error: 0.0453\n"
     ]
    }
   ],
   "source": [
    "history = conv_model.fit(x_train, labels_train, batch_size=32, shuffle=True, epochs=5, validation_data=(x_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.91396279],\n",
       "       [0.91396279, 1.        ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = conv_model.predict(x_test)\n",
    "preds = np.asarray([pred[0] for pred in preds])\n",
    "np.corrcoef(preds, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigger convolutional part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 256\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "big_conv_inputs = keras.Input(shape = (img_size[1], img_size[0], 3), name='robo_cam_frame')\n",
    "\n",
    "big_conv_layer = layers.Conv2D(64, kernel_size=3, activation='relu')(big_conv_inputs)\n",
    "big_conv_layer = layers.MaxPool2D(pool_size=(2,2))(big_conv_layer)\n",
    "\n",
    "big_conv_layer = layers.Conv2D(128, kernel_size=3, activation='relu')(big_conv_inputs)\n",
    "big_conv_layer = layers.MaxPool2D(pool_size=(2,2))(big_conv_layer)\n",
    "\n",
    "big_conv_x = layers.Flatten(name = 'flattened_features')(big_conv_layer)\n",
    "\n",
    "big_conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(big_conv_x)\n",
    "big_conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(big_conv_x)\n",
    "big_conv_outputs =  layers.Dense(1, activation='sigmoid', name='class')(big_conv_x)\n",
    "\n",
    "big_conv_model = keras.Model(inputs = big_conv_inputs, outputs = big_conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr = 1e-6)\n",
    "big_conv_model.compile(optimizer=customAdam, loss=\"binary_crossentropy\", metrics = [\"binary_crossentropy\", \"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6554 samples, validate on 1638 samples\n",
      "Epoch 1/5\n",
      "6554/6554 [==============================] - 505s 77ms/sample - loss: 0.4289 - binary_crossentropy: 0.4289 - mean_squared_error: 0.0731 - val_loss: 0.4543 - val_binary_crossentropy: 0.4543 - val_mean_squared_error: 0.1037\n",
      "Epoch 2/5\n",
      "6554/6554 [==============================] - 470s 72ms/sample - loss: 0.1337 - binary_crossentropy: 0.1337 - mean_squared_error: 0.0326 - val_loss: 0.3246 - val_binary_crossentropy: 0.3246 - val_mean_squared_error: 0.0751\n",
      "Epoch 3/5\n",
      "6554/6554 [==============================] - 448s 68ms/sample - loss: 0.2140 - binary_crossentropy: 0.2140 - mean_squared_error: 0.0431 - val_loss: 0.1919 - val_binary_crossentropy: 0.1919 - val_mean_squared_error: 0.0391\n",
      "Epoch 4/5\n",
      "6554/6554 [==============================] - 452s 69ms/sample - loss: 0.1321 - binary_crossentropy: 0.1321 - mean_squared_error: 0.0290 - val_loss: 0.0598 - val_binary_crossentropy: 0.0598 - val_mean_squared_error: 0.0159\n",
      "Epoch 5/5\n",
      "6554/6554 [==============================] - 450s 69ms/sample - loss: 0.0930 - binary_crossentropy: 0.0930 - mean_squared_error: 0.0197 - val_loss: 0.1080 - val_binary_crossentropy: 0.1080 - val_mean_squared_error: 0.0224\n"
     ]
    }
   ],
   "source": [
    "history = big_conv_model.fit(x_train, labels_train, batch_size=32, shuffle=True, epochs=5, validation_data=(x_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.95585357],\n",
       "       [0.95585357, 1.        ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_2 = big_conv_model.predict(x_test)\n",
    "preds_2 = np.asarray([pred[0] for pred in preds_2])\n",
    "np.corrcoef(preds_2, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigger NN part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_size = 512\n",
    "img_size = IMG_SIZE\n",
    "\n",
    "bigger_conv_inputs = keras.Input(shape=(img_size[1], img_size[0], 3), name='robo_cam_frame')\n",
    "\n",
    "bigger_conv_layer = layers.Conv2D(64, kernel_size = 3, activation='relu')(bigger_conv_inputs)\n",
    "bigger_conv_layer = layers.MaxPool2D(pool_size=(2,2))(bigger_conv_layer)\n",
    "\n",
    "bigger_conv_layer = layers.Conv2D(128, kernel_size = 3, activation='relu')(bigger_conv_layer)\n",
    "bigger_conv_layer = layers.MaxPool2D(pool_size=(2,2))(bigger_conv_layer)\n",
    "\n",
    "bigger_conv_x = layers.Flatten(name = 'flattened_features')(bigger_conv_layer)\n",
    "\n",
    "bigger_conv_x = layers.Dense(fc_layer_size, activation='relu', name='first_layer')(bigger_conv_x)\n",
    "bigger_conv_x = layers.Dense(fc_layer_size, activation='relu', name='second_layer')(bigger_conv_x)\n",
    "bigger_conv_outputs = layers.Dense(1, activation='sigmoid', name='class')(bigger_conv_x)\n",
    "\n",
    "bigger_conv_model = keras.Model(inputs = bigger_conv_inputs, outputs = bigger_conv_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "customAdam = keras.optimizers.Adam(lr = 1e-6)\n",
    "bigger_conv_model.compile(optimizer=customAdam, loss=\"binary_crossentropy\", metrics = [\"binary_crossentropy\", \"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6554 samples, validate on 1638 samples\n",
      "Epoch 1/5\n",
      "6554/6554 [==============================] - 347s 53ms/sample - loss: 0.5950 - binary_crossentropy: 0.5950 - mean_squared_error: 0.0935 - val_loss: 0.0991 - val_binary_crossentropy: 0.0991 - val_mean_squared_error: 0.0287\n",
      "Epoch 2/5\n",
      "6554/6554 [==============================] - 341s 52ms/sample - loss: 0.1074 - binary_crossentropy: 0.1074 - mean_squared_error: 0.0306 - val_loss: 0.0572 - val_binary_crossentropy: 0.0572 - val_mean_squared_error: 0.0166\n",
      "Epoch 3/5\n",
      "6554/6554 [==============================] - 327s 50ms/sample - loss: 0.0750 - binary_crossentropy: 0.0750 - mean_squared_error: 0.0210 - val_loss: 0.0539 - val_binary_crossentropy: 0.0539 - val_mean_squared_error: 0.0158\n",
      "Epoch 4/5\n",
      "6554/6554 [==============================] - 325s 50ms/sample - loss: 0.0593 - binary_crossentropy: 0.0593 - mean_squared_error: 0.0158 - val_loss: 0.0508 - val_binary_crossentropy: 0.0508 - val_mean_squared_error: 0.0148\n",
      "Epoch 5/5\n",
      "6554/6554 [==============================] - 324s 49ms/sample - loss: 0.0702 - binary_crossentropy: 0.0702 - mean_squared_error: 0.0191 - val_loss: 0.0381 - val_binary_crossentropy: 0.0381 - val_mean_squared_error: 0.0108\n"
     ]
    }
   ],
   "source": [
    "history = bigger_conv_model.fit(x_train, labels_train, batch_size=32, shuffle=True, epochs=5, validation_data=(x_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.97810496],\n",
       "       [0.97810496, 1.        ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_3 = bigger_conv_model.predict(x_test)\n",
    "preds_3 = np.asarray([pred[0] for pred in preds_3])\n",
    "np.corrcoef(preds_3, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
